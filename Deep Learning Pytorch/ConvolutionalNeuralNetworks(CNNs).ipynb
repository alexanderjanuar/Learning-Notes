{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution operator - OOP way\n",
    "\n",
    "**OOP - Based (torcn.nn)**\n",
    "- in_channels : number of channels in input\n",
    "- out_channels : number of output channels produced by convolution\n",
    "- kernel_size : size of convolution kernel\n",
    "- stride : stride of convolution. Default 1\n",
    "- padding : padding of convolution. Zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Create 10 random images of shape (1, 28, 28)\n",
    "images = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Build 6 conv. filters\n",
    "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Convolve the image with the filters \n",
    "output_feature = conv_filters(images)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution operator - Functional way\n",
    "\n",
    "**Functional - Based (torcn.nn.functional)**\n",
    "- input : input tensor of shape (batch,in_channels,Height,Width)\n",
    "- weights : filter of shape\n",
    "- stride : the stride of the convolution kernel. Can be a single number or a tuple (sH,sW)\n",
    "- padding : implicit zero padding on both sides of the input. Default 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Create 10 random images\n",
    "image = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Create 6 filters\n",
    "filters = torch.rand(6, 1, 3, 3)\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max-pooling operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[8., 5., 9.],\n",
      "          [9., 2., 6.],\n",
      "          [2., 9., 8.]]]])\n",
      "tensor([[[[8., 5., 9.],\n",
      "          [9., 2., 6.],\n",
      "          [2., 9., 8.]]]])\n"
     ]
    }
   ],
   "source": [
    "im = torch.tensor([[[[ 8.,  1.,  2.,  5.,  3.,  1.],\n",
    "                    [ 6.,  0.,  0., -5.,  7.,  9.],\n",
    "                    [ 1.,  9., -1., -2.,  2.,  6.],\n",
    "                    [ 0.,  4.,  2., -3.,  4.,  3.],\n",
    "                    [ 2., -1.,  4., -1., -2.,  3.],\n",
    "                    [ 2., -4.,  5.,  9., -7.,  8.]]]])\n",
    "\n",
    "# Build a pooling operator with size `2`.\n",
    "max_pooling = torch.nn.MaxPool2d(2)\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = max_pooling(im) # OOP - BASED\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = F.max_pool2d(im,2) # Functional - BASED\n",
    "\n",
    "# print the results of both cases\n",
    "print(output_feature)\n",
    "print(output_feature_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average-pooling operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOP - Based\n",
      "tensor([[[[ 3.7500,  0.5000,  5.0000],\n",
      "          [ 3.5000, -1.0000,  3.7500],\n",
      "          [-0.2500,  4.2500,  0.5000]]]])\n",
      "\n",
      "Functional - Based\n",
      "tensor([[[[ 3.7500,  0.5000,  5.0000],\n",
      "          [ 3.5000, -1.0000,  3.7500],\n",
      "          [-0.2500,  4.2500,  0.5000]]]])\n"
     ]
    }
   ],
   "source": [
    "# Build a pooling operator with size `2`.\n",
    "avg_pooling = torch.nn.AvgPool2d(2)\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = avg_pooling(im)\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = F.avg_pool2d(im, 2)\n",
    "\n",
    "# print the results of both cases\n",
    "print(\"OOP - Based\")\n",
    "print(output_feature)\n",
    "print(\"\\nFunctional - Based\")\n",
    "print(output_feature_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - init method\n",
    "\n",
    "- You are going to build your first convolutional neural network. You're going to use the MNIST dataset as the dataset, which is made of handwritten digits from 0 to 9. \n",
    "- The convolutional neural network is going to have 2 convolutional layers, each followed by a ReLU nonlinearity, and a fully connected layer. \n",
    "- Each pooling layer halves both the height and the width of the image, so by using 2 pooling layers, the height and width are 1/4 of the original sizes. MNIST images have shape (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Instantiate a max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = nn.Linear(7 * 7 * 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\t\t\n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Instantiate a max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = nn.Linear(7 * 7 * 10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Prepare the image for the fully connected layer\n",
    "        x = x.view(-1, 7 * 7 * 10)\n",
    "\n",
    "        # Apply the fully connected layer and return the result\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preapare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transform the data to torch tensors and normalize it \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])\n",
    "\n",
    "# Prepare training set and testing set\n",
    "trainset = torchvision.datasets.CIFAR10('Data', train=True, \n",
    "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10('Data', train=False,\n",
    "\t\t\t   download=True, transform=transform)\n",
    "\n",
    "# Prepare training loader and testing loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                          shuffle=False, num_workers=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\t\t\n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Instantiate a max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = nn.Linear(128 * 4 * 4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Prepare the image for the fully connected layer\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "\n",
    "        # Apply the fully connected layer and return the result\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.436, Accuracy: 37.13125\n",
      "Epoch 1, Batch 1000, Loss: 0.357, Accuracy: 48.61875\n",
      "Epoch 1, Batch 1500, Loss: 0.324, Accuracy: 54.38125\n",
      "Epoch 2, Batch 500, Loss: 0.292, Accuracy: 59.04375\n",
      "Epoch 2, Batch 1000, Loss: 0.276, Accuracy: 61.03125\n",
      "Epoch 2, Batch 1500, Loss: 0.266, Accuracy: 63.09375\n",
      "Epoch 3, Batch 500, Loss: 0.244, Accuracy: 65.6875\n",
      "Epoch 3, Batch 1000, Loss: 0.237, Accuracy: 67.175\n",
      "Epoch 3, Batch 1500, Loss: 0.233, Accuracy: 67.5875\n",
      "Epoch 4, Batch 500, Loss: 0.216, Accuracy: 70.2\n",
      "Epoch 4, Batch 1000, Loss: 0.215, Accuracy: 70.9\n",
      "Epoch 4, Batch 1500, Loss: 0.211, Accuracy: 70.83125\n",
      "Epoch 5, Batch 500, Loss: 0.198, Accuracy: 72.825\n",
      "Epoch 5, Batch 1000, Loss: 0.197, Accuracy: 72.9375\n",
      "Epoch 5, Batch 1500, Loss: 0.191, Accuracy: 73.625\n",
      "Epoch 6, Batch 500, Loss: 0.179, Accuracy: 75.5625\n",
      "Epoch 6, Batch 1000, Loss: 0.181, Accuracy: 75.39375\n",
      "Epoch 6, Batch 1500, Loss: 0.179, Accuracy: 75.25625\n",
      "Epoch 7, Batch 500, Loss: 0.164, Accuracy: 77.85625\n",
      "Epoch 7, Batch 1000, Loss: 0.166, Accuracy: 77.0375\n",
      "Epoch 7, Batch 1500, Loss: 0.167, Accuracy: 76.93125\n",
      "Epoch 8, Batch 500, Loss: 0.151, Accuracy: 79.88125\n",
      "Epoch 8, Batch 1000, Loss: 0.155, Accuracy: 78.81875\n",
      "Epoch 8, Batch 1500, Loss: 0.156, Accuracy: 78.18125\n",
      "Epoch 9, Batch 500, Loss: 0.139, Accuracy: 81.025\n",
      "Epoch 9, Batch 1000, Loss: 0.145, Accuracy: 80.03125\n",
      "Epoch 9, Batch 1500, Loss: 0.142, Accuracy: 80.45625\n",
      "Epoch 10, Batch 500, Loss: 0.126, Accuracy: 82.43125\n",
      "Epoch 10, Batch 1000, Loss: 0.133, Accuracy: 81.73125\n",
      "Epoch 10, Batch 1500, Loss: 0.135, Accuracy: 81.30625\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Adam optimizer and Cross-Entropy loss function\n",
    "model = Net(num_classes=10)   \n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the forward pass\n",
    "        outputs = model(inputs)\n",
    "            \n",
    "        # Compute the loss function\n",
    "        loss = criterion(outputs,labels)\n",
    "            \n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            accuracy = 100 * correct / total \n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 2000:.3f}, Accuracy: {accuracy}')\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 74.18%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    images, labels = data\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct / total}%')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
